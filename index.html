<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="google-site-verification" content="VqP1lG6BYTJ6SaMfg29j5rjWDMxLReOUu2HD_JeiSJA" />
	<title>Yaohui Wang</title>

	<link rel='icon' href='favicon.ico' type='image/x-icon'/>
	<link href="./css/bootstrap.min.css" rel="stylesheet">
        <link rel="stylesheet" href="./assets/academicons-1.7.0/css/academicons.css"/>
    	<link rel="stylesheet" href="./assets/font-awesome-4.7.0/css/font-awesome.min.css"/>
    </head>

    <body>

      <div style="height:10px;"></div>
      <!-- Navigation bar -->
      
      <div class="navbar navbar-default  navbar-fixed-top bg-info">
        <div class="container">
          <div class="navbar-header">
          
            <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
          </div>
          <div class="navbar-collapse collapse" id="navbar-main">
             
            <ul class="nav navbar-nav navbar-left">
              <li ><a href="index.html#aboutme">Home</a></li>
              <li ><a href="#research">Research</a></li>
              <li ><a href="#teaching">Teaching</a></li>
              <li ><a href="group.html">Group Seminar</a></li>
            </ul>
          </div>
        </div>
      </div>

      <div style="height:80px;"></div>
     

      <!-- end of navigation bar -->

      <!-- CONTENTS -->
      <div class="container">
        <!-- Aboutme -->
        <!--<div id="aboutme"></div> -->
        <div style="font-family: Times New Roman" class="row">
          <div class="col-xs-6 col-sm-4 col-md-2">
            <a class="thumbnail">
              <img src="./img/me.jpg" alt="Yaohui Wang" class="img-rounded">
            </a>            
          </div>

          <div class="col-xs-10 col-sm-6 col-md-4">
            <h1 class="text-info">Yaohui Wang 王耀晖</h1>
            <h4 class="text-info">Ph.D. Inria</h4>
	    <h5>
	    	<a href="mailto:wangyaohui@pjlab.org.cn" class="text-info" title="e-Mail"><i class="fa fa-envelope-square fa-2x"></i></a>
            	<a href="https://scholar.google.com/citations?user=R7LyAb4AAAAJ&hl=EN" class="text-info" title="Google Scholar"><i class="ai ai-google-scholar-square ai-2x"></i></a>
		<a href="https://github.com/wyhsirius" class="text-info" title="GitHub"><i class="fa fa-github-square fa-2x"></i></a>
            	<a href="https://www.linkedin.com/in/yaohui-wang-586983112" class="text-info" title="LinkedIn"><i class="fa fa-linkedin-square fa-2x"></i></a>
		<a href="https://twitter.com/yaohuiwang_yh" class="text-info" title="Twitter"><i class="fa fa-twitter-square fa-2x"></i></a>
	    </h5>
	    
		<img src="./img/inria.png" alt="inria" style="width:20%">
          </div>
        </div>
		
         
         <p style="font-family: Times New Roman" class="text-body", align="justify">
         I am a Research Scientist at <a href='' class="text-info">Shanghai Artificial Intelligence Laboratory</a>, where I work on <a href='' class="text-info">video generation</a>. My works include <a href='https://github.com/Vchitect/Latte' class="text-info">Latte</a>, <a href='https://vchitect.github.io/LaVie-project/' class="text-info">LaVie</a>, <a href='https://github.com/Vchitect/SEINE' class="text-info">SEINE</a>, <a href='https://github.com/guoyww/animatediff/' class="text-info">AnimateDiff</a>, <a href='https://github.com/wyhsirius/LIA' class="text-info">LIA</a> and <a href='https://github.com/wyhsirius/LEO-project' class="text-info">LEO</a>.<br> 
	</p>

	<p style="font-family: Times New Roman" class="text-body", align="justify">
	I obtained my PhD from <a href='https://www.inria.fr/fr/centre-inria-sophia-antipolis-mediterranee' class="text-info">Inria</a>, STARS team focusing on developing <a href='https://www.inria.fr/fr/centre-inria-sophia-antipolis-mediterranee' class="text-info">learning methods for video generation</a> advised by <a href='http://antitza.com' class="text-info">Antitza Dantcheva</a> and <a href='http://www-sop.inria.fr/members/Francois.Bremond/' class="text-info">Francois Bremond</a>. Before that, I completed Master <a href='https://sites.google.com/chalearn.org/ai-master' class='text-info'>Artificial Intelligence </a> program directed by <a href='https://guyon.chalearn.org/', class='text-info'>Isabelle Guyon</a> and <a href='https://www.lri.fr/~sebag/', class='text-info'>Michèle Sebag</a> from <a href='https://www.universite-paris-saclay.fr/en', class='text-info'>Université Paris-Saclay</a>.	
	</p>
	      
	    <p style="font-family: Times New Roman">
		<strong>I am looking for research interns on deep generative models for videos/3D/images. Feel free to <a href="mailto:wyhsirius@gmail.com" class="text-info">contact me</a> if you are interested.</strong> 
	    </p>
	
        <!-- News -->
        <div class="row" id="news" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>News</h2>
          </div>
        </div>	

	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">11 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  Talk at <a href="https://univ-cotedazur.eu/events/sophia-summit" class="text-info">SophIA Summit 2024</a>.
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">10 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  1 paper <a href="https://vchitect.github.io/LaVie" class="text-info">LaVie</a> accepted to <a href="" class="text-info">IJCV</a>.
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">10 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  1 paper <a href="" class="text-info">4Diffusion</a> accepted to <a href="" class="text-info">NeurIPS 2024.</a>
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">08 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  1 paper <a href="https://vchitect.github.io/LIA" class="text-info">LIA (Journal extension)</a> accepted to <a href="" class="text-info">TPAMI</a> and 1 paper <a href="https://vchitect.github.io/LEO-project" class="text-info">LEO</a> accepted to <a href="" class="text-info">IJCV</a>.
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">02 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  4 paper <a href="" class="text-info">VBench</a>, <a href="" class="text-info">EpiDiff</a>, <a href="" class="text-info">SinSR</a> and <a href="" class="text-info">Vlogger</a> accepted to <a href="" class="text-info">CVPR 2024</a>. 
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">01 / 2024</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  3 paper <a href="" class="text-info">SEINE</a>, <a href="" class="text-info">InternVid</a> and <a href="" class="text-info">AnimateDiff</a> accepted to <a href="https://aaai.org/aaai-conference/" class="text-info">ICLR 2024</a>. 
          </div>
	</div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">11 / 2023</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  2 paper <a href="" class="text-info">ConditionVideo</a> and <a href="" class="text-info">Diff-Text</a> accepted to <a href="https://aaai.org/aaai-conference/" class="text-info">AAAI 2024</a>. 
          </div>
        </div>
	<div style="height:3px;"></div>
	      
	<div style="font-family: Times New Roman"  class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">11 / 2023</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  A remote talk at <a href='https://charlotteml.github.io' class="text-info">CharMLab, UNC Charlotte</a> on <a href='' class="text-info">Large-scale Video Generation Models</a>. 
          </div>
        </div>
        <div style="height:3px;"></div>
	      
	<div style="font-family: Times New Roman" class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">07 / 2023</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  1 paper <a href="" class="text-info">LAC</a> accepted to <a href='' class="text-info">ICCV 2023</a>!  
          </div>
        </div>
        <div style="height:3px;"></div>
	      
	<div style="font-family: Times New Roman" class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">04 / 2023</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  1 paper <a href="" class="text-info">Loris</a> accepted to <a href='https://icml.cc/Conferences/2023/Dates' class="text-info">ICML 2023</a>!  
          </div>
        </div>
        <div style="height:3px;"></div>

	<!--
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">11 / 2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  One paper accepted to <a href='' class="text-info">TPAMI</a>!  
          </div>
        </div>
        <div style="height:3px;"></div>
	      
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">11 / 2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  Our work <a href='' class="text-info">Latent Time Navigation (LTN)</a> has been accepted to <a href='' class="text-info">AAAI 2023</a>.
          </div>
        </div>
        <div style="height:3px;"></div>      
	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">08 / 2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  Invited <a href='https://www.bilibili.com/video/BV1bT411F7v4/?from=search' class="text-info">talk</a> at GAMES Seminar on <class="text-info">Image Animation</a>. 
          </div>
        </div>
        <div style="height:3px;"></div>
	      
	      
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">01 / 2022</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  Our work <a href='https://openreview.net/forum?id=7r6kDq0mK_' class="text-info">Latent Image Animator (LIA)</a> has been accepted to <a href='' class="text-info">ICLR 2022</a>, <a href='https://github.com/wyhsirius/LIA' class="text-info">code</a> released.
          </div>
        </div>
        <div style="height:3px;"></div>
	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">10 / 2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  I have successfully defended my PhD!
          </div>
        </div>
        <div style="height:3px;"></div>
	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">10 / 2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  Our work <a href='https://arxiv.org/pdf/2107.08580.pdf' class="text-info">UNIK</a> has been accepted to <a href='https://www.bmvc2021.com/' class="text-info">BMVC 2021</a> as oral presentation, <a href='https://github.com/YangDi666/UNIK' class="text-info">code</a> released.
          </div>
        </div>
        <div style="height:3px;"></div>

	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">03 / 2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
                  One paper accepted by <a href='http://cvpr2021.thecvf.com/' class="text-info">CVPR 2021</a>, <a href='https://github.com/chenhao2345/GCL' class="text-info">code</a> released.
          </div>
        </div>
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">01 / 2021</span>
          </div>
          <div class="col-sm-11 col-md-11">
		  New work <a href='https://arXiv.org/pdf/2101.03049.pdf' class="text-info">InMoDeGAN</a> on Interpretable Unsupervised Video Generation is on arxiv.
          </div>
        </div>
        <div style="height:3px;"></div>

	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">12 / 2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
          New work <a href='https://arxiv.org/pdf/2012.09071.pdf' class="text-info">GCL</a> on Unsupervised Person Re-id using GAN-based multi-view data augmentation is on arxiv. 
          </div>
        </div>
        <div style="height:3px;"></div>

	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">12 / 2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
          One paper <a href='https://arxiv.org/pdf/2012.09071.pdf' class="text-info">Selective Spatio-Temporal Aggregation Based Pose Refinement System</a> accepted by <a href='http://wacv2021.thecvf.com/home' class="text-info">WACV 2021</a>, <a href='https://github.com/YangDi666/SSTA-PRS' class="text-info">code</a> released.
          </div>
        </div>
        <div style="height:3px;"></div>

        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">02 / 2020</span>
          </div>
          <div class="col-sm-11 col-md-11">
          One paper <a href='' class="text-info">G&sup3AN: Disentangling appearance and motion for video generation</a> accepted by <a href='http://cvpr2020.thecvf.com/' class="text-info">CVPR 2020</a>, <a href='https://github.com/wyhsirius/g3an-project' class="text-info">code</a> released.
          </div>
        </div>
        <div style="height:3px;"></div>
	
        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">10 / 2019</span>
          </div>
          <div class="col-sm-11 col-md-11">
			  I participated in PRAIRIE AI Summer School (<a href='https://project.inria.fr/paiss/speakers-2019/' class="text-info">PAISS 2019</a>) in Paris.
          </div>
        </div>
        <div style="height:3px;"></div>

        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">08 / 2019</span>
          </div>
          <div class="col-sm-11 col-md-11">
            Our paper <a href='' class="text-info">ImaGINator</a> has been accepted in <a href="http://wacv20.wacv.net" class="text-info">WACV 2020</a>.
          </div>
        </div>
        <div style="height:3px;"></div>

        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-success">02 / 2019</span>
          </div>
          <div class="col-sm-11 col-md-11">
            <a href=""></a>
          </div>
        </div>
        <div style="height:3px;"></div>

        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">09 / 2018</span>
          </div>
          <div class="col-sm-11 col-md-11">
            <a href="">Code</a> for <a href=""></a> is released.
          </div>
        </div>
        <div style="height:3px;"></div>
	
	<div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">08 / 2018</span>
          </div>
          <div class="col-sm-11 col-md-11">
            I visited Visual Information Processing and Learning group (<a href='http://vipl.ict.ac.cn' class="text-info">VIPL</a>) of Chinese Academy of Science in Beijing, China.
          </div>
        </div>
        <div style="height:3px;"></div>

		<div class="row">
          <div class="col-sm-1 col-md-1">
			  <span class="label label-info">07 / 2018</span>
          </div>
          <div class="col-sm-11 col-md-11">
			  I participated in PRAIRIE AI Summer School (<a href='https://project.inria.fr/paiss/speakers-2018/' class="text-info">PAISS 2018</a>) in Grenoble.
          </div>
        </div>
        <div style="height:3px;"></div>	
			
        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">05 / 2018</span>
          </div>
          <div class="col-sm-11 col-md-11">
			  Two papers accepted in <a href='https://eccv2018.org' class="text-info">ECCV 2018</a> workshops.
          </div>
        </div>
        <div style="height:3px;"></div>
        
        <div class="row">
          <div class="col-sm-1 col-md-1">
            <span class="label label-info">12 / 2017</span>
          </div>
          <div class="col-sm-11 col-md-11">
			  I joined <a href='' class="text-info">STARS</a> team, Inria Sophia-antipolis as a PhD student. 
          </div>
        </div>
        <div style="height:3px;"></div>
-->
        <!-- end of news -->

        <!-- Research -->
        <div style="font-family: Times New Roman" class="row"  id="research" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>Research</h2>(*equal contribution, <sup>&dagger;</sup>correspondance & project lead)
<!--Latte-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/latte.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Latte: Latent Diffusion Transformer for Video Generation</strong><br>
                Xin Ma, <u>Yaohui Wang</u><sup>&dagger;</sup>, Xinyuan Chen, Gengyun Jia, Ziwei Liu, Yuan-fang Li, Cunjian Chen, Yu Qiao<br>
                <em>arXiv:2401.03048</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2401.03048v1", class="text-info">Arxiv</a> |
                <a href="https://maxin-cn.github.io/latte_project/", class='text-info'>Project page</a> |
                <a href="https://github.com/Vchitect/Latte", class="text-info"class="text-info">Code</a> |
		<a href="https://huggingface.co/spaces/maxin-cn/Latte-1", class="text-info"class="text-info">Hugging face</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--LaVie-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/lavie.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>LaVie: High-Quality Video Generation with Cascaded Latent Diffusion Models</strong><br>
                <u>Yaohui Wang*</u>, Xinyuan Chen*, Xin Ma*, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, Yuwei Guo, Tianxing Wu, Chenyang Si, Yuming Jiang, Cunjian Chen, Chen Change Loy, Bo Dai, Dahua Lin<sup>&dagger;</sup>, Yu Qiao<sup>&dagger;</sup>, Ziwei Liu<sup>&dagger;</sup><br>
                <em>In IJCV 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2309.15103", class="text-info">Arxiv</a> |
                <a href="https://vchitect.github.io/LaVie-project/", class='text-info'>Project page</a> |
                <a href="https://github.com/Vchitect/LaVie", class="text-info"class="text-info">Code</a> |
		<a href="https://huggingface.co/spaces/Vchitect/LaVie", class="text-info"class="text-info">Hugging face</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--Cinemo-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/cinemo.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models</strong><br>
                Xin Ma, <u>Yaohui Wang</u><sup>&dagger;</sup>, Gengyun Jia, Xinyuan Chen, Yuan-fang Li, Cunjian Chen<sup>&dagger;</sup>, Yu Qiao<br>
                <em>arXiv:2407.15642</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2407.15642", class="text-info">Arxiv</a> |
                <a href="https://maxin-cn.github.io/cinemo_project/", class='text-info'>Project page</a> |
                <a href="https://github.com/maxin-cn/Cinemo", class="text-info"class="text-info">Code</a> |
		<a href="https://huggingface.co/spaces/maxin-cn/Cinemo", class="text-info"class="text-info">Hugging face</a>
                <div style="height:30px;"></div>
              </div>
            </div>


<!--4Diffusion-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/4diffusion.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>4Diffusion: Multi-view Video Diffusion Model for 4D Generation</strong><br>
                Haiyu Zhang, Xinyuan Chen, <u>Yaohui Wang</u>, Xihui Liu, Yunhong Wang, Yu Qiao<sup>&dagger;</sup><br>
                <em>In Proc. NeurIPS, Vancouver, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2405.20674", class="text-info">Arxiv</a> |
                <a href="https://aejion.github.io/4diffusion/", class='text-info'>Project page</a> |
                <a href="https://github.com/aejion/4Diffusion", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--SEINE-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/seine.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction</strong><br>
                Xinyuan Chen*, <u>Yaohui Wang*</u>, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin<sup>&dagger;</sup>, Yu Qiao<sup>&dagger;</sup>, Ziwei Liu<sup>&dagger;</sup><br>
                <em>In Proc. ICLR, Vienna, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2310.20700", class="text-info">Arxiv</a> |
                <a href="https://vchitect.github.io/SEINE-project/", class='text-info'>Project page</a> |
                <a href="https://github.com/Vchitect/SEINE", class="text-info"class="text-info">Code</a> |
		<a href=https://huggingface.co/spaces/Vchitect/SEINE", class="text-info"class="text-info">Hugging face</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--VBench-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/vbench.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>VBench: Comprehensive Benchmark Suite for Video Generative Models</strong><br>
                Ziqi Huang, Yinan He, Jiashuo Yu, Fan Zhang, Chenyang Si, Yuming Jiang, Yuanhan Zhang, Tianxing Wu, Qingyang Jin, Nattapol Chanpaisit, <u>Yaohui Wang</u>, Xinyuan Chen, Limin Wang, Dahua Lin, Yu Qiao and Ziwei Liu<br>
                <em>In Proc. CVPR, Seattle, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2311.17982.pdf", class="text-info">Arxiv</a> |
                <a href="https://vchitect.github.io/VBench-project/", class='text-info'>Project page</a> |
                <a href="https://github.com/Vchitect/VBench", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--EpiDiff-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/epidiff.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>EpiDiff:Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion</strong><br>
                Zehuan Huang, Hao Wen, Junting Dong, <u>Yaohui Wang</u>, Yangguang Li, Xinyuan Chen, Yan-pei Cao, Ding Liang, Yu Qiao, Bo Dai and Lu Sheng<br>
                <em>In Proc. CVPR, Seattle, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2312.06725.pdf", class="text-info">Arxiv</a> |
                <a href="https://huanngzh.github.io/EpiDiff/", class='text-info'>Project page</a> |
                <a href="", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--SinSR-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/sinsr.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>SinSR: Diffusion-Based Image Super-Resolution in a Single Step</strong><br>
                Yufei Wang, Wenhan Yang, Xinyuan Chen, <u>Yaohui Wang</u>, Lanqing Guo, Lap-Pui Chau, Ziwei Liu, Yu Qiao, Alex C. Kot and Bihan Wen<br>
                <em>In Proc. CVPR, Seattle, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2311.14760.pdf", class="text-info">Arxiv</a> |
                <a href="https://github.com/wyf0912/SinSR/", class='text-info'>Project page</a> |
                <a href="https://github.com/wyf0912/SinSR/", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>


<!--vlogger-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/vlogger.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Vlogger: Make Your Dream A Vlog</strong><br>
                Shaobin Zhuang, Kunchang Li, Xinyuan Chen, <u>Yaohui Wang</u>, Ziwei Liu, Yu Qiao, Yali Wang<br>
                <em>In Proc. CVPR, Seattle, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2401.09414.pdf", class="text-info">Arxiv</a> |
                <a href="https://Vlogger.github.io", class='text-info'>Project page</a> |
                <a href="https://github.com/Vchitect/Vlogger", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

		  
<!--difftext-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/difftext.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model</strong><br>
                Lingjun Zhang, Xinyuan Chen, <u>Yaohui Wang</u>, Yue Lu, Yu Qiao<br>
                <em>In Proc. AAAI, Vancouver, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="", class="text-info">Arxiv</a> |
                <a href="", class='text-info'>Project page</a> |
                <a href="", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--ConditionVideo-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/conditionvideo.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation</strong><br>
                Bo Peng, Xinyuan Chen, <u>Yaohui Wang</u>, Chaochao Lu, Yu Qiao<br>
                <em>In Proc. AAAI, Vancouver, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2310.07697", class="text-info">Arxiv</a> |
                <a href="https://pengbo807.github.io/conditionvideo-website/", class='text-info'>Project page</a> |
                <a href="https://github.com/pengbo807/ConditionVideo", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--LAC-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/lac.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>LAC: Latent Action Composition for Skeleton-based Action Segmentation</strong><br>
                Di Yang, <u>Yaohui Wang</u><sup>&dagger;</sup>, Antitza Dantcheva, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond. <sup>&dagger;</sup>corresponding author<br>
                <em>In Proc. ICCV, Paris, 2023</em></br>
                <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2308.14500", class="text-info">Arxiv</a> |
                <a href="https://walker1126.github.io/LAC/", class='text-info'>Project page</a> |
                <a href="https://github.com/walker1126/Latent_Action_Composition", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--InternVid-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/internvid.jpeg">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation</strong><br>
                Yi Wang*, Yinan He*, Yuzhuo Li*, Kunchang Li, Jiashuo Yu, Xin Ma, Xinyuan Chen, <u>Yaohui Wang</u>, Ping Luo, Ziwei Liu, Yali Wang<sup>&dagger;</sup>, Limin Wang<sup>&dagger;</sup>, Yu Qiao<sup>&dagger;</sup><br>
                <em>In Proc. ICLR, Vienna, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2307.06942.pdf", class="text-info">Arxiv</a> |
                <a href="https://github.com/OpenGVLab/InternVideo/tree/main/Data/InternVid", class='text-info'>Project page</a> |
                <a href="https://github.com/OpenGVLab/InternVideo/tree/main/Data/InternVid", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--AnimateDiff-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/animatediff.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</strong><br>
                Yuwei Guo, Ceyuan Yang, Anyi Rao, <u>Yaohui Wang</u>, Yu Qiao, Dahua Lin, Bo Dai<br>
                <em>In Proc. ICLR, Vienna, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2307.04725", class="text-info">Arxiv</a> |
                <a href="https://animatediff.github.io/", class='text-info'>Project page</a> |
                <a href="https://github.com/guoyww/animatediff/", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--LEO-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/leo.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>LEO: Generative Latent Image Animator for Human Video Synthesis</strong><br>
                <u>Yaohui Wang</u>, Xin Ma, Xinyuan Chen, Cunjian Chen, Antitza Dancheva, Bo Dai, Yu Qiao<br>
                <em>In IJCV 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2305.03989", class="text-info">Arxiv</a> |
                <a href="https://wyhsirius.github.io/LEO-project/", class='text-info'>Project page</a> |
                <a href="https://github.com/wyhsirius/LEO", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--HDAE-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/hdae.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Hierarchical Diffusion Autoencoders and Disentangled Image Manipulation</strong><br>
                Zeyu Lu, Chengyue Wu, Xinyuan Chen, <u>Yaohui Wang</u>, Lei Bai, Yu Qiao, Xihui Liu<br>
                <em>In Proc. WACV, Hawaii, 2024</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2304.11829", class="text-info">Arxiv</a> |
                <a href="", class='text-info'>Project page</a> |
                <a href="", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
<!--LORIS-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/loris.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Long-Term Rhythmic Video Soundtracker</strong><br>
                Jiashuo Yu, <u>Yaohui Wang</u>, Xinyuan Chen, Xiao Sun, Yu Qiao<br>
                <em>In Proc. ICML, Hawaii, 2023</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2305.01319", class="text-info">Arxiv</a> |
                <a href='', class='text-info'>Project page</a> |
                <a href="https://github.com/OpenGVLab/LORIS", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
		  
<!--LTN-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/LTN.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Self-supervised Video Representation Learning via Latent Time Navigation</strong><br>
                Di Yang, <u>Yaohui Wang</u>, Quan Kong, Antitza Dantcheva, Lorenzo Garattoni, Gianpiero Francesca and François Brémond<br>
                <em>In Proc. AAAI, Washington, 2023</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="", class="text-info">Arxiv</a> |
                <a href='', class='text-info'>Project page</a> |
                <a href="", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!--ViA-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/via.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>ViA: View-invariant Skeleton Action Representation Learning via Motion Retargeting</strong><br>
                Di Yang, <u>Yaohui Wang</u><sup>&dagger;</sup>, Antitza Dantcheva, Lorenzo Garattoni, Gianpiero Francesca and François Brémond<br>
                <em>In IJCV, 2023</em></br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://arxiv.org/abs/2209.00065", class="text-info">Arxiv</a> |
                <a href='https://walker-a11y.github.io/ViA-project/', class='text-info'>Project page</a> |
                <a href="", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
		  
		  
<!--LIA-->
        <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/LIA.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Latent Image Animator: Learning to Animate Images via Latent Space Navigation</strong><br>
                <u>Yaohui Wang</u>, Di Yang, Francois Bremond and Antitza Dantcheva<br>
                <em>In Proc. ICLR, Virtual, 2022</em></br>
		<strong>LIA: Latent Image Animator</strong><br>
                <u>Yaohui Wang</u>, Di Yang, Francois Bremond and Antitza Dantcheva<br>
                <em>In TPAMI, 2024</em></br>
                <a href="https://openreview.net/pdf?id=7r6kDq0mK_", class="text-info">Paper</a> |
		<a href="https://ieeexplore.ieee.org/document/10645735/", class="text-info">Paper (TPAMI version)</a> |
                <a href="https://arxiv.org/abs/2203.09043", class="text-info">Arxiv</a> |
                <a href='http://wyhsirius.github.io/LIA-project/', class='text-info'>Project page</a> |
                <a href="https://github.com/wyhsirius/LIA", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>


<!--UNIK-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/unik.png">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>UNIK: A Unified Framework for Real-world Skeleton-based Action Recognition</strong><br>
		Di Yang*, <u>Yaohui Wang*</u>, Antitza Dantcheva, Lorenzo Garattoni, Gianpiero Francesca and Francois Bremond. *equal contribution<br>
                <em>In Proc. BMVC, Virtual, 2021 (Oral)</em></br>
		<a href="http://www-sop.inria.fr/members/Francois.Bremond/Postscript/Di-bmvc2021.pdf", class="text-info">Paper</a> |
                <a href="https://arxiv.org/pdf/2107.08580.pdf", class="text-info">Arxiv</a> |
		<a href='https://yangdi666.github.io/UNIK-project/', class='text-info'>Project page</a> |
                <a href="https://github.com/YangDi666/UNIK", class="text-info"class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>

<!-- inmodegan -->
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="img/inmodegan.gif">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
		<strong>InMoDeGAN: Interpretable Motion Decomposition Generative Adversarial Network for Video Generation</strong><br>
                <u>Yaohui Wang</u>, Francois Bremond, and Antitza Dantcheva<br>
		<em>arXiv:2101.03049</em></br>
                <a href="https://arxiv.org/pdf/2101.03049.pdf", class="text-info">Arxiv</a> |
                <a href="https://wyhsirius.github.io/InMoDeGAN/", class="text-info"class="text-info">Project page</a> |
                <a href="https://github.com/wyhsirius/InMoDeGAN-project", class="text-info"class="text-info">Code</a>
		<div style="height:30px;"></div>
              </div>
            </div>
<!-- end of inmodegan -->


<!-- GCL -->
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="./img/gcl.png"> 
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Joint Generative and Contrastive Learning for Unsupervised Person Re-identification</strong><br>
		Hao Chen*, <u>Yaohui Wang*</u>, Benoit Lagadec, Antitza Dantcheva, and Francois Bremond. *equal contribution<br>
                <em>In Proc. CVPR, Virtual,</em> 2021.<br>
		<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Joint_Generative_and_Contrastive_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.pdf", class="text-info">Paper</a> |
                <a href="https://github.com/chenhao2345/GCL", class="text-info">Code</a><br>
		<strong>Learning Invariance from Generated Variance or Unsupervised Person Re-identification</strong><br>
		<em>In IEEE TPAMI, </em> 2022.<br>
                <a href="", class="text-info">Paper</a> |
                <a href="https://github.com/chenhao2345/GCL", class="text-info">Code</a>
                <div style="height:30px;"></div>
              </div>
            </div>
<!-- end of GCL -->


<!-- SSTA-PRS -->
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail">
                 <img src="./img/ssta.png"> 
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Selective Spatio-Temporal Aggregation Based Pose Refinement System</strong><br>
                Di Yang, Rui Dai, <u>Yaohui Wang</u>, Rupayan Mallick, Luca Minciullo, Gianpiero Francesca, and Francois Bremond<br>
                <em>In Proc. WACV, Virtual,</em> 2021.<br>
                <a href="https://arxiv.org/pdf/2011.05358.pdf", class="text-info">Paper</a> |
		<a href="https://github.com/YangDi666/SSTA-PRS", class="text-info">Code</b></a>
                <div style="height:30px;"></div>
              </div>
            </div>
<!-- end of GCL -->


<!-- G3AN -->
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/g3an.png" alt="G&sup3AN: Disentangling appearance and motion for video generation">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>G&sup3AN: Disentangling appearance and motion for video generation</strong><br>
                <u>Yaohui Wang</u>, Piotr Bilinski, Francois Bremond, and Antitza Dantcheva<br>
                <em>In Proc. CVPR, Seattle, US,</em> 2020.<br>
		<em>In LUV-CVPR Workshop, Seattle, US,</em> 2020. (Oral Presentation)<br>
                <a href="https://arxiv.org/pdf/1912.05523.pdf", class="text-info">Paper</button></a> |
                <a href="https://wyhsirius.github.io/G3AN/". class="text-info">Project page</a> |
		<a href="https://github.com/wyhsirius/g3an-project". class="text-info">Code</a> |
                <a href="https://www.youtube.com/watch?v=jEXbmxGKFfQ", class="text-info">Video</a>
		<div style="height:30px;"></div>
              </div>
            </div>
<!-- end of G3AN -->

<!-- ImaGINator -->
            <div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/imaginator.png" alt="ImaGINator: Conditional Spatio-Temporal GAN for Video Generation">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>ImaGINator: Conditional Spatio-Temporal GAN for Video Generation</strong><br>
		<u>Yaohui Wang</u>, Piotr Bilinski, Francois Bremond, and Antitza Dantcheva<br>
                <em>In Proc. WACV, Aspen, US,</em> 2020.<br>
                <a href="http://openaccess.thecvf.com/content_WACV_2020/papers/WANG_ImaGINator_Conditional_Spatio-Temporal_GAN_for_Video_Generation_WACV_2020_paper.pdf", class="text-info">Paper</a> |
                <a href="https://github.com/wyhsirius/ImaGINator", class="text-info">Code</a> |
                <a href="img/imaginator.mp4", class="text-info">Video</a>
		<div style="height:30px;"></div>
              </div>
            </div>
<!-- end of ImaGINator -->

<!--FG20-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/fg20.png" alt="A video is worth more than 1000 lies. Comparing 3DCNN approaches for detecting deepfakes">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>A video is worth more than 1000 lies. Comparing 3DCNN approaches for detecting deepfakes</strong><br>
		<u>Yaohui Wang</u> and Antitza Dantcheva<br>
                <em>In Proc. FG, Buenos Aires, Argentina,</em> 2020.<br>
                <a href="http://antitza.com/19.wang_fg_20.pdf", class="text-info">Paper</a>
		<div style="height:30px;"></div>
              </div>
            </div>

<!--FA2F-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/fa2f.png" alt="From attribute-labels to faces: face generation using a conditional generative adversarial network">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>From attribute-labels to faces: face generation using a conditional generative adversarial network</strong><br>
		<u>Yaohui Wang</u>, Antitza Dantcheva and Francois Bremond<br>
                <em>In Proc. ECCV Workshop, Munich, Germany,</em> 2018.<br>
                <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Wang_From_attribute-labels_to_faces_face_generation_using_a_conditional_generative_ECCVW_2018_paper.pdf", class="text-info">Paper</a>
		<div style="height:30px;"></div>
              </div>
            </div>

<!--eccvw18-->
	<div class="row">
              <div class="col-xs-10 col-sm-4 col-md-4">
                <a class="thumbnail" href="">
                  <img src="./img/eccvw18.png" alt="Comparing methods for assessment of facial dynamics in patients with major neurocognitive disorders">
                </a>
              </div>
              <div class="col-xs-12 col-sm-8 col-md-8">
                <strong>Comparing methods for assessment of facial dynamics in patients with major neurocognitive disorders</strong><br>
		<u>Yaohui Wang</u>, Antitza Dantcheva, Francois Bremond and Piotr Bilinski<br>
                <em>In Proc. ECCV Workshop, Munich, Germany,</em> 2018.<br>
                <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11134/Wang_Comparing_methods_for_assessment_of_facial_dynamics_in_patients_with_ECCVW_2018_paper.pdf", class="text-info">Paper</a>
		<div style="height:30px;"></div>
              </div>
            </div>

		  
 		<div class="row" id="teaching" style="padding-top:60px; margin-top:-60px;">
         <div class="col-md-12">
           <h2>PhD Thesis</h2>
           <div class="col-xs-6 col-sm-4 col-md-3">
             <a class="thumbnail">
               <img src="./img/thesis.png" alt="thesis" class="img-rounded">
             </a>
			             
           </div>
                 <div class="col-xs-12 col-sm-8 col-md-8">
                   <strong>Learning to Generate Human Videos</strong><br>
   				   Yaohui Wang<br>
				   <a href="https://hal.inria.fr/tel-03551913v1", class="text-info">Thesis</a><br><br>
				   Defense Jury:
				   <ul>
					   <li><a href="http://www-sop.inria.fr/members/George.Drettakis/", class="text-info">George Drettakis (President)</a>, Inria Sophia Antipolis, France</li>
					   <li><a href="https://www.di.ens.fr/~laptev/", class="text-info">Ivan Laptev</a>, Inria Paris/École normale supérieure, France </li>
					   <li><a href="http://elisaricci.eu/", class="text-info">Elisa Ricci</a>, University of Trento, Italy</li>
					   <li><a href="https://people.ucas.edu.cn/~sgshan?language=en", class="text-info">Shiguang Shan</a>, Chinese Academy of Sciences, China</li>
					   <li><a href="http://www.stulyakov.com/", class="text-info">Sergey Tulyakov</a>, Snap Research, USA</li>
					   <li><a href="https://scholar.google.com/citations?user=RKt2sFIAAAAJ&hl=zh-CN", class="text-info">Panayiotis Georgiou</a>, Apple Inc./University of Southern California, USA</li>
				   </ul>
                   
		   
 		</div>
	</div>
	
	
	 	<div class="row" id="teaching" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>Professional activities</h2>
            <div class="row">
				<div class="col-sm-1 col-md-1">
                  <span class="label label-info"> Reviewer </span>
              	</div>
				<div class="col-sm-11 col-md-11">
                	 SIGGRAPH 2022, CVPR 2022/2021, ECCV 2022/2020, WACV 2020 ...
              	</div>
				</div>
            
	  	</div>
	 	</div>


        <!-- Teaching -->
        <div class="row" id="teaching" style="padding-top:60px; margin-top:-60px;">
          <div class="col-md-12">
            <h2>Teaching</h2>
            <div class="row">
	      <div class="col-sm-1 col-md-1">
                <span class="label label-info">Winter 2021</span>
              </div>
              <div class="col-sm-11 col-md-11">
                <a href="http://www-sop.inria.fr/members/Francois.Bremond/MSclass/deepLearningWinterSchool21/UCA_master/index.html" class="text-info">Deep Learning for Computer Vision</a>, Lecture and TA, <a href="http://univ-cotedazur.fr/en/idex/formations-idex/data-science/" class="text-info">MSc of Data Science and Artificial Intelligence</a>, 3IA Cote d'Azur
              </div>

              <div class="col-sm-1 col-md-1">
                <span class="label label-info">Winter 2020</span>
              </div>
              <div class="col-sm-11 col-md-11">
                <a href="http://www-sop.inria.fr/members/Francois.Bremond/MSclass/deepLearningWinterSchool/UCA_master/index.html" class="text-info">Deep Learning for Computer Vision</a>, Lecture and TA, <a href="http://univ-cotedazur.fr/en/idex/formations-idex/data-science/" class="text-info">MSc of Data Science and Artificial Intelligence</a>, 3IA Cote d"Azur
              </div>
            </div>

          </div> 
        </div> <!-- end of teaching -->

	
      </div> <!-- end of contents -->
      <hr>


      <div class="container">
        <footer>
          <p align="right"><small>Copyright © Yaohui Wang</small></p>
        </footer>
        <div style="height:10px;"></div>
      </div>

      <!-- Bootstrap core JavaScript -->
      <!-- Placed at the end of the document so the pages load faster -->
      <script src="jq/jquery-1.11.1.min.js"></script>
      <script src="js/bootstrap.min.js"></script>
      <script src="js/docs.min.js"></script>

    </body>
</html>
